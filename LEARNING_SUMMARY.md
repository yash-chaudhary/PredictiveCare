
## Learning Summary
Starting off with Microsoft's learn modules, I got a good introduction into the machine learning lifecycle and why it had been split up into the data phase, model phase and the production phase. Despite being new to machine learning and artificial intelligence, I stuck to this framework and I think its safe to say it worked like a charm. During my preliminary testing I tinkered with Azure's Machine Learning Studios to create some basic regression, classification and clustering models to give myself a feel for what I would need to do both in the data phase and model phase. 

After about a week of testing and tinkering with different Azure services, I was ready to start working on the ideation phase to flesh my projects functions and what it aims to achieve while in the spirit of leverageing AI and ML. I used Kaggle to find a dataset that was related to my idea and having no experience with Jupyter Notebooks I again spent some more time testing out the features of this new tool that in the end would help me a great deal in the data and model phases. I was able to do pre-processing on the dataset and do some analysis on the performance of the different models I tested which were all centred around classification (Naive Bayes, Random Forest and Decision Trees).

In the end I really enjoyed the ease and performance of Azure's Automated ML in Azure Machine Learning Studios. As I mentioned before, I was thinking about how I would scale my AI/ML and my application. It turns out that Automatd ML automates the pre-processing stage by trying many different pre-processing technqiues automatically all the while running a variety of machine learning models in parallel to find the best performing model. The ability of Automated ML to automate the pre-processing and training process definitely makes my application highly scalable as retraining, an important part of the machine learning lifecyle, is done with ease with Automated ML. To top if off, I was able to understand why Automated ML picked the best model that it did and after doing some additional digging into the final model, I was ready to produce and application. Automated ML allowed me to deploy my model as a REST endpoint thus futhering the scalability of my final application as the REST endpoint is stateless and doesn't store anything meaning it doesn't require much communication between servers. 

I personally have had experience with building fullstack web applications but I've never used Flask before which was the backend I chose for this project. This was to improve the factor of extensibilty as many other Azure services could be built into my web application in the future. So I ended up learning flask and ended up thoroughly enjoying it as the easiest backend framework I've worked with so far. On the front end I used react which is a framework I am very fond off. To keep with the spirit of scalability I kepy my model deployed in the cloud and also since its worked so well. 

Of course my key learnings can be summarised as mainly to do with the machine learning aspect of my project. I learned how to following the machine learning lifecyle to built a great end prodict, I learnt how to use AI/ML libraries and Jupyter Notebooks to generate my own models and do analysis on them and how to build a Flask backend and integrate it with a React.js frontend. One of the main lessons I've learnt is the importance of good data. Without a good dataset my application would be doomed and would not work as well as it has. This was a really fun project and I've learnt to much with regards to AI and ML. 

